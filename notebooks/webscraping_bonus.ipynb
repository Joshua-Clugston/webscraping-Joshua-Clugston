{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07101fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import sleep # this is to create a time delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f871ec",
   "metadata": {},
   "source": [
    "# 1. Navigate to https://www.billboard.com/charts/hot-100/. Using BeautifulSoup, extract out the This Week, artist, song, Last Week, Peak Position, and Weeks on Chart values into a pandas DataFrame. Hint: The HTML for the number one ranked song is slightly different from that of the rest of the songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd707db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.billboard.com/charts/hot-100/'\n",
    "\n",
    "response = requests.get(URL)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89626b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d6e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h3').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67abcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = soup.findAll('h3')\n",
    "titles = []\n",
    "for song in songs:\n",
    "    meta_data = str(song)\n",
    "    #print(meta_data)\n",
    "    \n",
    "    pattern = re.compile('a-no-trucate')\n",
    "    \n",
    "    if pattern.search(meta_data):\n",
    "        song_cleaned = re.subn('[\\n\\t]', '', song.text)[0]\n",
    "        #print(f'Result: \"{song_cleaned}\" is a song!\\n')\n",
    "        titles.append(re.subn('[\\n\\t]', '', song.text)[0])\n",
    "    #else:\n",
    "    #    print('Result: It is not a song\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e930ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db07285",
   "metadata": {},
   "source": [
    "### Now to collect the other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = soup.findAll('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e585c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(spans))\n",
    "spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6477f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('lrv-u-padding-tb-050@mobile-max')\n",
    "span_filter = []\n",
    "\n",
    "for span in spans:\n",
    "    span_text = str(span)\n",
    "    #print(span_text,'\\nNEW ENTRY\\n')\n",
    "    if pattern.search(span_text):\n",
    "        span_filter.append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "span_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(span_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21558c2",
   "metadata": {},
   "source": [
    "There are 3 entries of data for each song that we are not using. As such, I'll use a loop to filter which data to use and where we'll put it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e6fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "last_week = []\n",
    "peak_pos = []\n",
    "weeks_on_chart = []\n",
    "\n",
    "\n",
    "for span in span_filter:\n",
    "    if i%6 == 1:\n",
    "        last_week.append(span.text.strip('\\n\\t'))\n",
    "    elif i%6 == 2:\n",
    "        peak_pos.append(span.text.strip('\\n\\t'))\n",
    "        print()\n",
    "    elif i%6 == 3:\n",
    "        weeks_on_chart.append(span.text.strip('\\n\\t'))\n",
    "\n",
    "    i += 1\n",
    "#end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d66fe",
   "metadata": {},
   "source": [
    "### Let me explain this loop\n",
    "\n",
    "When I was cycling through the instances of the elements found in span_filter, I noticed that every 4th, 5th, and 6th entry was not visible on the website, meaning I had to disregard it. What this function is doing is just that: disregarding every 4th, 5th, and 6th element.\n",
    "\n",
    "This is done using %. This is commonly referred to as \"modulus\" to math people like myself, but don't worry if that term scares you. The concept is very easy: it gives you remainders when you divide.\n",
    "\n",
    "For instance, 5/2 = 2.5, but 5%2 = 1. This is because 2 goes into 5 a total of 2 times, but has a remainder of 1. Since the remainder is 1, that is what % returns. Weird right? Who would've thought that dividing with remainders would be used anywhere outside of elementary school?\n",
    "\n",
    "Anyway, since there are 3 data points I need and 3 that I don't, I created an iterable variable (which is 'i') to keep track of which data point I was on. The reason I use i%6 is beacuse each song has 6 data points (again, with 3 that I need and 3 that I need to disregard). As such, I was able to succesfully filter out the ones I didn't need and assign the ones I did need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36524503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(last_week))\n",
    "last_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dba09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(peak_pos))\n",
    "peak_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab07294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(weeks_on_chart))\n",
    "weeks_on_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d10142",
   "metadata": {},
   "source": [
    "### Creating the Data Frame to add to later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8734e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.DataFrame(titles)\n",
    "songs_df.columns = ['Title']\n",
    "songs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc078104",
   "metadata": {},
   "source": [
    "### Finding the artists for each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('a-no-trucate')\n",
    "artists = []\n",
    "\n",
    "for span in spans:\n",
    "    span_text = str(span)\n",
    "    #print(span_text,'\\nNEW ENTRY\\n')\n",
    "    if pattern.search(span_text):\n",
    "        artists.append(span.text.strip('\\n\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464bbd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0860e98",
   "metadata": {},
   "source": [
    "### Finding rankings of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('u-letter-spacing-0080@tablet')\n",
    "ranks = []\n",
    "\n",
    "for span in spans:\n",
    "    span_text = str(span)\n",
    "    #print(span_text,'\\nNEW ENTRY\\n')\n",
    "    if pattern.search(span_text):\n",
    "        ranks.append(span.text.strip('\\n\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e81e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01232826",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df['Rank'] = ranks\n",
    "songs_df = songs_df.set_index('Rank')\n",
    "songs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fac08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df['Artist(s)'] = artists\n",
    "songs_df['Last Week'] = last_week\n",
    "songs_df['Peak Position'] = peak_pos\n",
    "songs_df['Weeks on Chart'] = weeks_on_chart\n",
    "songs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2bbf5a",
   "metadata": {},
   "source": [
    "# 2. After getting the code working for the current chart, navigate to last week's chart. Notice how the url for the page changes. Write a function which will, given a date, return a pandas DataFrame containing the Billboard chart data for that date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32b594",
   "metadata": {},
   "source": [
    "The url changes based on whatever was the last day of the week (for instance, 2023-11-04 was a Saturday, so that date represents the entire week). So what I need to do is, given a date, determine if it is Saturday, and if not, how to find the Saturday of the same week. This could be a case statement (if day_name == 'Tuesday': day = day+4), although it does seem to be inefficient. Oh well, I'm gonna try that anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f481ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199333a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_1 = DateTime.datetime.strptime(day_str, \"%Y-%m-%d\")\n",
    "\n",
    "end_date = date_1 + DateTime.timedelta(days=1)\n",
    "print(end_date.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_hot_100(day): ### day must be in format YYYY-MM-DD\n",
    "#    date = DateTime.datetime.strptime(day, '%Y-%m-%d')\n",
    "\n",
    "#    day_num = date.weekday()\n",
    "#    print(day_num)\n",
    "    \n",
    "#    if day_num != 5:\n",
    "#        if day_num < 5:\n",
    "#            day_delta = 5 - date.weekday()\n",
    "#            date = date + DateTime.timedelta(days=day_delta)\n",
    "#        else:\n",
    "#            date = date + DateTime.timedelta(days=6)\n",
    "#    print(date.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db490395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_hot_100('2023-11-05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_day = DateTime.datetime.strptime('2023-11-13', '%Y-%m-%d')\n",
    "some_day.weekday()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59982b98",
   "metadata": {},
   "source": [
    "## After all of this hard work, I found out that you can just put the date in the URL. I'm so sad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_100(date): # date must be in format YYYY-MM-DD\n",
    "    date = str(date) # If it isn't already\n",
    "    \n",
    "    URL = 'https://www.billboard.com/charts/hot-100/' + date\n",
    "    \n",
    "    response = requests.get(URL)\n",
    "    soup = BS(response.text)\n",
    "    \n",
    "    ### Titles\n",
    "    songs = soup.findAll('h3')\n",
    "    titles = []\n",
    "\n",
    "    for song in songs:\n",
    "        meta_data = str(song)\n",
    "\n",
    "        pattern = re.compile('a-no-trucate')\n",
    "\n",
    "        if pattern.search(meta_data):\n",
    "            song_cleaned = re.subn('[\\n\\t]', '', song.text)[0]\n",
    "            titles.append(re.subn('[\\n\\t]', '', song.text)[0])\n",
    "    #end\n",
    "    \n",
    "    ### Defining spans\n",
    "    spans = soup.findAll('span')\n",
    "    \n",
    "    pattern = re.compile('lrv-u-padding-tb-050@mobile-max')\n",
    "    span_filter = []\n",
    "\n",
    "    for span in spans:\n",
    "        span_text = str(span)\n",
    "        \n",
    "        if pattern.search(span_text):\n",
    "            span_filter.append(span)\n",
    "    #end\n",
    "    \n",
    "    ### The Modulus Loop\n",
    "    i = 1\n",
    "    last_week = []\n",
    "    peak_pos = []\n",
    "    weeks_on_chart = []\n",
    "\n",
    "    for span in span_filter:\n",
    "        if i%6 == 1:\n",
    "            last_week.append(span.text.strip('\\n\\t'))\n",
    "        elif i%6 == 2:\n",
    "            peak_pos.append(span.text.strip('\\n\\t'))\n",
    "        elif i%6 == 3:\n",
    "            weeks_on_chart.append(span.text.strip('\\n\\t'))\n",
    "\n",
    "        i += 1\n",
    "    #end\n",
    "    \n",
    "    ### Artists\n",
    "    pattern = re.compile('a-no-trucate')\n",
    "    artists = []\n",
    "\n",
    "    for span in spans:\n",
    "        span_text = str(span)\n",
    "\n",
    "        if pattern.search(span_text):\n",
    "            artists.append(span.text.strip('\\n\\t'))\n",
    "    #end\n",
    "    \n",
    "    ### Ranks\n",
    "    pattern = re.compile('u-letter-spacing-0080@tablet')\n",
    "    ranks = []\n",
    "\n",
    "    for span in spans:\n",
    "        span_text = str(span)\n",
    "    \n",
    "        if pattern.search(span_text):\n",
    "            ranks.append(span.text.strip('\\n\\t'))\n",
    "    #end  \n",
    "    \n",
    "    ### Creating the Data Frame\n",
    "    songs_df = pd.DataFrame(titles)\n",
    "    songs_df.columns = ['Title']\n",
    "    songs_df['Rank'] = ranks\n",
    "    songs_df = songs_df.set_index('Rank')\n",
    "    songs_df['Artist(s)'] = artists\n",
    "    songs_df['Last Week'] = last_week\n",
    "    songs_df['Peak Position'] = peak_pos\n",
    "    songs_df['Weeks on Chart'] = weeks_on_chart\n",
    "    \n",
    "    return songs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158a64e",
   "metadata": {},
   "source": [
    "# 3. Write a loop to retrieve the Billboard chart data for the last 10 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a07444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today = DateTime.datetime.today()\n",
    "\n",
    "for i in range(1,11): # range is left exclusive, so we use 11 to include 10\n",
    "    #print(i)\n",
    "    date = today - DateTime.timedelta(weeks=i)\n",
    "    print(date.date())\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    song_df = get_hot_100(str(date.date()))\n",
    "    dataframes.append(song_df)\n",
    "#end\n",
    "\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7e9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
